---

## üß© √âtapes du pipeline MLOps

### 1Ô∏è‚É£ Acquisition des donn√©es (`src/load_data.py`)
- T√©l√©chargement du jeu **Sentiment140** (1,6 M de tweets).
- Extraction et filtrage des colonnes pertinentes (`sentiment`, `text`).
- Conversion des labels :  
  - `0 ‚Üí n√©gatif`  
  - `4 ‚Üí positif`  
- √âchantillonnage de 50 000 tweets pour des raisons de performance.

‚û°Ô∏è R√©sultat : `data/raw_tweets.csv`

---

### 2Ô∏è‚É£ Pr√©traitement du texte (`src/preprocess.py`)
- Nettoyage du texte (URLs, mentions, hashtags, chiffres, ponctuation).  
- Conversion en minuscules.  
- Tokenisation et suppression des stopwords (`nltk`).
- Lemmatisation (`WordNetLemmatizer`).
- S√©paration **train/test (80/20)** de mani√®re stratifi√©e.  

‚û°Ô∏è R√©sultat :  
`data/train.csv` et `data/test.csv`

---

### 3Ô∏è‚É£ Entra√Ænement des mod√®les (`src/train.py`)
Deux mod√®les ont √©t√© entra√Æn√©s √† l‚Äôaide d‚Äôun **pipeline scikit-learn** combinant :
- **Vectorisation TF-IDF** : repr√©sentation des mots selon leur importance locale et globale.
- **Mod√®les compar√©s** :
  - **R√©gression Logistique (Logistic Regression)** ‚Üí mod√®le *discriminatif*.
  - **Naive Bayes Multinomial (MultinomialNB)** ‚Üí mod√®le *g√©n√©ratif*.

‚û°Ô∏è R√©sultat :  
`models/logistic_regression_pipeline.joblib`  
`models/naive_bayes_pipeline.joblib`

---

### 4Ô∏è‚É£ √âvaluation des performances (`src/evaluate.py`)
- Chargement des jeux de test et des mod√®les sauvegard√©s.  
- G√©n√©ration de rapports de classification (`precision`, `recall`, `f1-score`, `accuracy`).  
- Comparaison quantitative entre les deux mod√®les.

#### üßÆ R√©sultats obtenus :

| Mod√®le                   | Accuracy | F1-score (pond√©r√©) |
|---------------------------|-----------|--------------------|
| R√©gression Logistique     | **0.7507** | **0.7506**         |
| Naive Bayes               | 0.7443    | 0.7443             |

‚úÖ Ces r√©sultats confirment la sup√©riorit√© de la R√©gression Logistique sur des donn√©es textuelles riches, en accord avec la th√©orie.

---

## ‚öôÔ∏è Installation et ex√©cution

### üîß 1. Cloner le d√©p√¥t
```bash
git clone https://github.com/nicolaspscl/mlops-tp.git
cd mlops-tp


Creer l'environnement virtuel 
python3 -m venv venv
source venv/bin/activate  # macOS / Linux
venv\Scripts\activate     # Windows

Installer les d√©pendances 
requirements.txt

Executer le pipeline complet 
python src/load_data.py
python src/preprocess.py
python src/train.py
python src/evaluate.py
